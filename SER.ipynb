{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0r9v-DC8ySB"
      },
      "source": [
        "!pip install playsound\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io.wavfile as wavfile\n",
        "import os\n",
        "import librosa\n",
        "from playsound import playsound\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "# Model libraries\n",
        "import keras\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZljMjL6EjYf"
      },
      "source": [
        "# Global variables\n",
        "emotions = {'ANG' : 0, 'DIS' : 1, 'FEA' : 2, 'HAP' : 3, 'NEU' : 4, 'SAD' : 5}\n",
        "# data used for play_audio functions to get classes of the audio\n",
        "data = {}\n",
        "# zero-crossing rate and mel spectrogram feature spaces\n",
        "x_zcr = []\n",
        "x_mel = []\n",
        "# labels of dataset\n",
        "y = []  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSGpt02GIdXT"
      },
      "source": [
        "# **Reading** **Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukG2Lpff_C6l"
      },
      "source": [
        "def scan_folder(parent):\n",
        "  classes = []\n",
        "  curr_word = \"1001_DFA\"\n",
        "  # iterate over all the files in directory 'parent'\n",
        "  m = 0\n",
        "  for file_name in sorted(os.listdir(parent)):\n",
        "    print(m)\n",
        "    m+=1\n",
        "    file_path = parent + '/' + file_name\n",
        "    #print(file_path)\n",
        "    word = file_name[0:8]\n",
        "    if curr_word != word:  \n",
        "      data[curr_word] = classes\n",
        "      classes = []\n",
        "      curr_word = word\n",
        "    classes.append(file_path)\n",
        "    # Create zero crossing rate, mel spectrogram feature space and labels array\n",
        "    x, sr = librosa.load(file_path)\n",
        "    zcr = librosa.feature.zero_crossing_rate(x)\n",
        "    mel = librosa.feature.melspectrogram(x)\n",
        "    x_zcr.append(zcr)\n",
        "    x_mel.append(mel)\n",
        "    y.append(emotions[file_path.split('/')[4][9:12]])\n",
        "scan_folder('drive/MyDrive/PR assignment 3/Crema')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b0SvOH920DK"
      },
      "source": [
        "# **Playing the audio and plotting the wave form**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbP8n6SgCQvO"
      },
      "source": [
        "def play_audio(audio):\n",
        "  for x in data[audio]:\n",
        "    print('Playing audio for file '+x.split('/')[1]+\":\\n\")\n",
        "    playsound(x)\n",
        "    # read audio samples\n",
        "    input_data = wavfile.read(x)\n",
        "    audio = input_data[1]\n",
        "    # plot the first 1024 samples\n",
        "    plt.plot(audio)\n",
        "    # label the axes\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "    plt.xlabel(\"Time\")\n",
        "    # set the title  \n",
        "    plt.title(x.split('/')[1][0:12])\n",
        "    # display the plot\n",
        "    plt.show()\n",
        "#play_audio(\"1001_DFA\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6CcLoM53IL9"
      },
      "source": [
        "# **Zero Padding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t68YGZ-qQmy3"
      },
      "source": [
        "def zero_padding(): #zero padding is needed to match dimensions for the model\n",
        "  global x_mel\n",
        "  global x_zcr\n",
        "  global y\n",
        "\n",
        "  \n",
        "   #Zero padding for zcr list\n",
        "  for i in range(len(x_zcr)):\n",
        "    zero_padding = np.zeros((1,216))\n",
        "    zero_padding[:x_zcr[i].shape[0],:x_zcr[i].shape[1]] = x_zcr[i]\n",
        "    x_zcr[i] = zero_padding\n",
        "  x_zcr = np.array(x_zcr)\n",
        "  print(\"Zero crossing rate shape: \",x_zcr.shape)\n",
        "\n",
        "\n",
        "  # Zero padding for mel spectrogram list\n",
        "  for i in range(len(x_mel)):\n",
        "    zero_padding = np.zeros((128,216))\n",
        "    zero_padding[:x_mel[i].shape[0],:x_mel[i].shape[1]] = x_mel[i]\n",
        "    x_mel[i] = zero_padding\n",
        "  x_mel = np.array(x_mel)\n",
        "  print(\"Mel spectrogram shape: \",x_mel.shape)\n",
        "\n",
        "  # Converting y to numpy array\n",
        "  y = np.array(y)\n",
        "  print(\"Labels shape: \",y.shape)\n",
        "\n",
        "\n",
        "zero_padding()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdEA9hIc3daL"
      },
      "source": [
        "# **Data Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QjPuTgPkdd4"
      },
      "source": [
        "def noise(data):\n",
        "    \"\"\"\n",
        "    Adding White Noise.\n",
        "    \"\"\"\n",
        "    # you can take any distribution from https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.random.html\n",
        "    noise_amp = 0.005*np.random.uniform()*np.amax(data)\n",
        "    data = data.astype('float64') + noise_amp * np.random.normal(size=data.shape)\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql_ZJnzAymGS"
      },
      "source": [
        "# **Models**\n",
        "\n",
        "1.   Model using ZCR as feature space\n",
        "2.   Model using Mel Spectrogram as feature space\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G89o3HHP4Awk"
      },
      "source": [
        "# **1. ZCR Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwZa6W6X17pu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fa17dbbc-7f25-4e65-ce40-f3a8061cf154"
      },
      "source": [
        "def train_model_zcr():\n",
        "  #Splitting data 70% training , 30% testing\n",
        "  x_zcr_train, x_zcr_test, y_zcr_train, y_zcr_test = train_test_split(x_zcr, y, test_size=0.3, random_state=42)\n",
        "  # Reshaping training data\n",
        "  x_zcr_train = x_zcr_train.reshape(-1, 216, 1)\n",
        "  x_zcr_test = x_zcr_test.reshape(-1, 216, 1)\n",
        "  # Normalizing data\n",
        "  #x_zcr_train = x_zcr_train.astype('float32')\n",
        "  #x_zcr_test = x_zcr_test.astype('float32')\n",
        "  #x_mel_train = librosa.util.normalize(x_mel_train)\n",
        "  #x_mel_test = librosa.util.normalize(x_mel_test)\n",
        "  #x_zcr_train = x_zcr_train / 255.\n",
        "  #x_zcr_test = x_zcr_test / 255.\n",
        "  \n",
        "  #print(x_mel_train.shape, x_mel_test.shape,y_mel_train[0],y_mel_test[0])\n",
        "  #print(x_mel_train.shape, x_mel_test.shape)\n",
        "\n",
        "  #Splitting training data 5% validation\n",
        "  x_zcr_train, x_zcr_valid, y_zcr_train, y_zcr_valid = train_test_split(x_zcr_train, y_zcr_train, test_size=0.05, random_state=42)\n",
        "\n",
        "  #Data Augmentation to reduce overfitting\n",
        "  #Noise\n",
        "  print(\"Before augmentation training x and y size: \",x_zcr_train.shape,y_zcr_train.shape)\n",
        "  noise_arr = []\n",
        "  for i in range(x_zcr_train.shape[0]):\n",
        "    noise_arr.append(noise(x_zcr_train[i]))\n",
        "  noise_arr = np.array(noise_arr)\n",
        "  x_zcr_train = np.append(x_zcr_train,noise_arr,axis=0) \n",
        "  y_zcr_train = np.append(y_zcr_train,y_zcr_train)\n",
        "  print(\"After augmentation training x and y size: \",x_zcr_train.shape,y_zcr_train.shape)\n",
        "  print(x_zcr_train.shape, x_zcr_test.shape,x_zcr_valid.shape,y_zcr_valid.shape)\n",
        "\n",
        "  # Change the labels from categorical to one-hot encoding\n",
        "  y_zcr_train = to_categorical(y_zcr_train)\n",
        "  y_zcr_test = to_categorical(y_zcr_test)\n",
        "  y_zcr_valid = to_categorical(y_zcr_valid)\n",
        "\n",
        "  # Building model\n",
        "  zcr_model = Sequential()\n",
        "  zcr_model.add(Conv1D(32, kernel_size=3,activation='relu',input_shape=(216,1),padding='valid'))\n",
        "  zcr_model.add(Conv1D(32, kernel_size=3,activation='relu',padding='valid'))\n",
        "  #zcr_model.add(Conv1D(32, kernel_size=3,activation='relu',padding='valid'))\n",
        "  zcr_model.add(MaxPooling1D(2,padding='valid'))\n",
        "  zcr_model.add(Dropout(0.25))\n",
        "  zcr_model.add(Conv1D(64, kernel_size=3,activation='relu',padding='valid'))\n",
        "  zcr_model.add(Conv1D(64, kernel_size=3,activation='relu',padding='valid'))\n",
        "  #zcr_model.add(BatchNormalization())\n",
        "  zcr_model.add(MaxPooling1D(2,padding='valid'))\n",
        "  zcr_model.add(Dropout(0.25))\n",
        "  zcr_model.add(Conv1D(128, kernel_size=3,activation='relu',padding='valid'))\n",
        "  zcr_model.add(Conv1D(128, kernel_size=3,activation='relu',padding='valid'))\n",
        "  #zcr_model.add(BatchNormalization())\n",
        "  zcr_model.add(MaxPooling1D(2,padding='valid'))\n",
        "  zcr_model.add(Dropout(0.25))\n",
        "  #mel_model.add(BatchNormalization())\n",
        "  zcr_model.add(MaxPooling1D(2,padding='valid'))\n",
        "  zcr_model.add(Dropout(0.25))\n",
        "  zcr_model.add(Conv1D(256, kernel_size=3,activation='relu',padding='valid'))\n",
        "  zcr_model.add(Conv1D(256, kernel_size=3,activation='relu',padding='valid'))\n",
        "  zcr_model.add(Conv1D(256, kernel_size=3,activation='relu',padding='valid'))\n",
        "  #zcr_model.add(BatchNormalization())\n",
        "  zcr_model.add(MaxPooling1D(2,padding='valid'))\n",
        "  zcr_model.add(Dropout(0.25))\n",
        "  zcr_model.add(Flatten())\n",
        "  zcr_model.add(Dense(128, activation='relu'))\n",
        "  #zcr_model.add(BatchNormalization())\n",
        "  zcr_model.add(Dropout(0.25))\n",
        "  zcr_model.add(Dense(6, activation='softmax'))\n",
        "  # Compiling model using ADAM optimizer\n",
        "  adam = keras.optimizers.Adam(learning_rate=0.00001)\n",
        "  zcr_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=adam,metrics=['accuracy'])\n",
        "  # Model summary\n",
        "  print(\"\\nModel Inspection\\n\")\n",
        "  zcr_model.summary()\n",
        "  # Training model\n",
        "  print(\"\\nModel training\\n\")\n",
        "  zcr_train_history = zcr_model.fit(x_zcr_train, y_zcr_train, batch_size=32,epochs=225,verbose=2,validation_data=(x_zcr_valid, y_zcr_valid))\n",
        "\n",
        "  # Plotting the Train Valid Loss Graph\n",
        "  plt.plot(zcr_train_history.history['loss'])\n",
        "  plt.plot(zcr_train_history.history['val_loss'])\n",
        "  plt.title('Model Loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  # Calculating accuracy of model\n",
        "  score = zcr_model.evaluate(x_zcr_test, y_zcr_test)\n",
        "  print(\"\\nTest loss = \",score[0])\n",
        "  print(\"Accuracy of the model = \",score[1])\n",
        "  predicted_classes = zcr_model.predict(x_zcr_test)\n",
        "  predicted_classes = np.argmax(predicted_classes, axis=1)\n",
        "  y_zcr_test = np.argmax(y_zcr_test, axis=1)\n",
        "  print(\"F-score of the model = \",f1_score(y_zcr_test,predicted_classes,average='macro'))\n",
        "  print(\"Confusion Matrix: \")\n",
        "  print(confusion_matrix(y_zcr_test,predicted_classes))\n",
        "\n",
        "train_model_zcr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before augmentation training x and y size:  (4948, 216, 1) (4948,)\n",
            "After augmentation training x and y size:  (9896, 216, 1) (9896,)\n",
            "(9896, 216, 1) (2233, 216, 1) (261, 216, 1) (261,)\n",
            "\n",
            "Model Inspection\n",
            "\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_31 (Conv1D)           (None, 214, 32)           128       \n",
            "_________________________________________________________________\n",
            "conv1d_32 (Conv1D)           (None, 212, 32)           3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_19 (MaxPooling (None, 106, 32)           0         \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 106, 32)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_33 (Conv1D)           (None, 104, 64)           6208      \n",
            "_________________________________________________________________\n",
            "conv1d_34 (Conv1D)           (None, 102, 64)           12352     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_20 (MaxPooling (None, 51, 64)            0         \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 51, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_35 (Conv1D)           (None, 49, 128)           24704     \n",
            "_________________________________________________________________\n",
            "conv1d_36 (Conv1D)           (None, 47, 128)           49280     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_21 (MaxPooling (None, 23, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 23, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_22 (MaxPooling (None, 11, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 11, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_37 (Conv1D)           (None, 9, 256)            98560     \n",
            "_________________________________________________________________\n",
            "conv1d_38 (Conv1D)           (None, 7, 256)            196864    \n",
            "_________________________________________________________________\n",
            "conv1d_39 (Conv1D)           (None, 5, 256)            196864    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_23 (MaxPooling (None, 2, 256)            0         \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 2, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 6)                 774       \n",
            "=================================================================\n",
            "Total params: 654,502\n",
            "Trainable params: 654,502\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Model training\n",
            "\n",
            "Epoch 1/225\n",
            "310/310 - 57s - loss: 1.7913 - accuracy: 0.1838 - val_loss: 1.7907 - val_accuracy: 0.1877\n",
            "Epoch 2/225\n",
            "310/310 - 2s - loss: 1.7868 - accuracy: 0.1767 - val_loss: 1.7809 - val_accuracy: 0.1877\n",
            "Epoch 3/225\n",
            "310/310 - 2s - loss: 1.7693 - accuracy: 0.1902 - val_loss: 1.7570 - val_accuracy: 0.2146\n",
            "Epoch 4/225\n",
            "310/310 - 2s - loss: 1.7562 - accuracy: 0.2386 - val_loss: 1.7467 - val_accuracy: 0.2950\n",
            "Epoch 5/225\n",
            "310/310 - 2s - loss: 1.7428 - accuracy: 0.2680 - val_loss: 1.7316 - val_accuracy: 0.2989\n",
            "Epoch 6/225\n",
            "310/310 - 2s - loss: 1.7251 - accuracy: 0.2748 - val_loss: 1.7083 - val_accuracy: 0.2989\n",
            "Epoch 7/225\n",
            "310/310 - 2s - loss: 1.7106 - accuracy: 0.2838 - val_loss: 1.6911 - val_accuracy: 0.3027\n",
            "Epoch 8/225\n",
            "310/310 - 2s - loss: 1.7001 - accuracy: 0.2962 - val_loss: 1.6710 - val_accuracy: 0.3142\n",
            "Epoch 9/225\n",
            "310/310 - 2s - loss: 1.6884 - accuracy: 0.3009 - val_loss: 1.6576 - val_accuracy: 0.3180\n",
            "Epoch 10/225\n",
            "310/310 - 2s - loss: 1.6782 - accuracy: 0.3033 - val_loss: 1.6439 - val_accuracy: 0.3448\n",
            "Epoch 11/225\n",
            "310/310 - 2s - loss: 1.6660 - accuracy: 0.3065 - val_loss: 1.6323 - val_accuracy: 0.3410\n",
            "Epoch 12/225\n",
            "310/310 - 2s - loss: 1.6568 - accuracy: 0.3154 - val_loss: 1.6183 - val_accuracy: 0.3410\n",
            "Epoch 13/225\n",
            "310/310 - 2s - loss: 1.6484 - accuracy: 0.3205 - val_loss: 1.6057 - val_accuracy: 0.3295\n",
            "Epoch 14/225\n",
            "310/310 - 2s - loss: 1.6384 - accuracy: 0.3232 - val_loss: 1.5947 - val_accuracy: 0.3487\n",
            "Epoch 15/225\n",
            "310/310 - 2s - loss: 1.6332 - accuracy: 0.3224 - val_loss: 1.5856 - val_accuracy: 0.3410\n",
            "Epoch 16/225\n",
            "310/310 - 2s - loss: 1.6258 - accuracy: 0.3245 - val_loss: 1.5855 - val_accuracy: 0.3487\n",
            "Epoch 17/225\n",
            "310/310 - 2s - loss: 1.6229 - accuracy: 0.3289 - val_loss: 1.5713 - val_accuracy: 0.3410\n",
            "Epoch 18/225\n",
            "310/310 - 2s - loss: 1.6183 - accuracy: 0.3301 - val_loss: 1.5634 - val_accuracy: 0.3563\n",
            "Epoch 19/225\n",
            "310/310 - 2s - loss: 1.6111 - accuracy: 0.3351 - val_loss: 1.5527 - val_accuracy: 0.3525\n",
            "Epoch 20/225\n",
            "310/310 - 2s - loss: 1.6027 - accuracy: 0.3365 - val_loss: 1.5469 - val_accuracy: 0.3525\n",
            "Epoch 21/225\n",
            "310/310 - 2s - loss: 1.6022 - accuracy: 0.3396 - val_loss: 1.5460 - val_accuracy: 0.3793\n",
            "Epoch 22/225\n",
            "310/310 - 2s - loss: 1.5931 - accuracy: 0.3430 - val_loss: 1.5383 - val_accuracy: 0.3716\n",
            "Epoch 23/225\n",
            "310/310 - 2s - loss: 1.5925 - accuracy: 0.3449 - val_loss: 1.5363 - val_accuracy: 0.3678\n",
            "Epoch 24/225\n",
            "310/310 - 2s - loss: 1.5906 - accuracy: 0.3427 - val_loss: 1.5328 - val_accuracy: 0.3755\n",
            "Epoch 25/225\n",
            "310/310 - 2s - loss: 1.5876 - accuracy: 0.3417 - val_loss: 1.5292 - val_accuracy: 0.3793\n",
            "Epoch 26/225\n",
            "310/310 - 2s - loss: 1.5866 - accuracy: 0.3428 - val_loss: 1.5271 - val_accuracy: 0.3755\n",
            "Epoch 27/225\n",
            "310/310 - 2s - loss: 1.5823 - accuracy: 0.3493 - val_loss: 1.5240 - val_accuracy: 0.3946\n",
            "Epoch 28/225\n",
            "310/310 - 2s - loss: 1.5787 - accuracy: 0.3478 - val_loss: 1.5182 - val_accuracy: 0.3946\n",
            "Epoch 29/225\n",
            "310/310 - 2s - loss: 1.5834 - accuracy: 0.3499 - val_loss: 1.5177 - val_accuracy: 0.3908\n",
            "Epoch 30/225\n",
            "310/310 - 2s - loss: 1.5757 - accuracy: 0.3491 - val_loss: 1.5196 - val_accuracy: 0.3793\n",
            "Epoch 31/225\n",
            "310/310 - 2s - loss: 1.5785 - accuracy: 0.3497 - val_loss: 1.5123 - val_accuracy: 0.3870\n",
            "Epoch 32/225\n",
            "310/310 - 2s - loss: 1.5737 - accuracy: 0.3559 - val_loss: 1.5127 - val_accuracy: 0.3870\n",
            "Epoch 33/225\n",
            "310/310 - 2s - loss: 1.5727 - accuracy: 0.3533 - val_loss: 1.5090 - val_accuracy: 0.3831\n",
            "Epoch 34/225\n",
            "310/310 - 2s - loss: 1.5734 - accuracy: 0.3546 - val_loss: 1.5077 - val_accuracy: 0.3831\n",
            "Epoch 35/225\n",
            "310/310 - 2s - loss: 1.5688 - accuracy: 0.3559 - val_loss: 1.5144 - val_accuracy: 0.3793\n",
            "Epoch 36/225\n",
            "310/310 - 2s - loss: 1.5708 - accuracy: 0.3569 - val_loss: 1.5090 - val_accuracy: 0.3946\n",
            "Epoch 37/225\n",
            "310/310 - 2s - loss: 1.5664 - accuracy: 0.3578 - val_loss: 1.4989 - val_accuracy: 0.3908\n",
            "Epoch 38/225\n",
            "310/310 - 2s - loss: 1.5667 - accuracy: 0.3514 - val_loss: 1.5050 - val_accuracy: 0.3716\n",
            "Epoch 39/225\n",
            "310/310 - 2s - loss: 1.5628 - accuracy: 0.3594 - val_loss: 1.4992 - val_accuracy: 0.3831\n",
            "Epoch 40/225\n",
            "310/310 - 2s - loss: 1.5609 - accuracy: 0.3616 - val_loss: 1.4995 - val_accuracy: 0.3793\n",
            "Epoch 41/225\n",
            "310/310 - 2s - loss: 1.5652 - accuracy: 0.3602 - val_loss: 1.4977 - val_accuracy: 0.3831\n",
            "Epoch 42/225\n",
            "310/310 - 2s - loss: 1.5608 - accuracy: 0.3658 - val_loss: 1.4962 - val_accuracy: 0.3831\n",
            "Epoch 43/225\n",
            "310/310 - 2s - loss: 1.5578 - accuracy: 0.3622 - val_loss: 1.4924 - val_accuracy: 0.3985\n",
            "Epoch 44/225\n",
            "310/310 - 2s - loss: 1.5577 - accuracy: 0.3645 - val_loss: 1.4944 - val_accuracy: 0.3870\n",
            "Epoch 45/225\n",
            "310/310 - 2s - loss: 1.5567 - accuracy: 0.3613 - val_loss: 1.4901 - val_accuracy: 0.3908\n",
            "Epoch 46/225\n",
            "310/310 - 2s - loss: 1.5570 - accuracy: 0.3647 - val_loss: 1.4915 - val_accuracy: 0.3985\n",
            "Epoch 47/225\n",
            "310/310 - 2s - loss: 1.5538 - accuracy: 0.3704 - val_loss: 1.4899 - val_accuracy: 0.3870\n",
            "Epoch 48/225\n",
            "310/310 - 2s - loss: 1.5541 - accuracy: 0.3626 - val_loss: 1.4909 - val_accuracy: 0.3908\n",
            "Epoch 49/225\n",
            "310/310 - 2s - loss: 1.5499 - accuracy: 0.3722 - val_loss: 1.4891 - val_accuracy: 0.3831\n",
            "Epoch 50/225\n",
            "310/310 - 2s - loss: 1.5527 - accuracy: 0.3651 - val_loss: 1.4853 - val_accuracy: 0.3946\n",
            "Epoch 51/225\n",
            "310/310 - 2s - loss: 1.5466 - accuracy: 0.3683 - val_loss: 1.4836 - val_accuracy: 0.4023\n",
            "Epoch 52/225\n",
            "310/310 - 2s - loss: 1.5516 - accuracy: 0.3682 - val_loss: 1.4832 - val_accuracy: 0.3870\n",
            "Epoch 53/225\n",
            "310/310 - 2s - loss: 1.5432 - accuracy: 0.3714 - val_loss: 1.4784 - val_accuracy: 0.4061\n",
            "Epoch 54/225\n",
            "310/310 - 2s - loss: 1.5456 - accuracy: 0.3667 - val_loss: 1.4793 - val_accuracy: 0.4023\n",
            "Epoch 55/225\n",
            "310/310 - 2s - loss: 1.5445 - accuracy: 0.3708 - val_loss: 1.4832 - val_accuracy: 0.3985\n",
            "Epoch 56/225\n",
            "310/310 - 2s - loss: 1.5457 - accuracy: 0.3708 - val_loss: 1.4810 - val_accuracy: 0.3870\n",
            "Epoch 57/225\n",
            "310/310 - 2s - loss: 1.5438 - accuracy: 0.3729 - val_loss: 1.4773 - val_accuracy: 0.4061\n",
            "Epoch 58/225\n",
            "310/310 - 2s - loss: 1.5405 - accuracy: 0.3755 - val_loss: 1.4778 - val_accuracy: 0.4023\n",
            "Epoch 59/225\n",
            "310/310 - 2s - loss: 1.5408 - accuracy: 0.3676 - val_loss: 1.4805 - val_accuracy: 0.3946\n",
            "Epoch 60/225\n",
            "310/310 - 2s - loss: 1.5419 - accuracy: 0.3746 - val_loss: 1.4805 - val_accuracy: 0.3946\n",
            "Epoch 61/225\n",
            "310/310 - 2s - loss: 1.5393 - accuracy: 0.3691 - val_loss: 1.4762 - val_accuracy: 0.3870\n",
            "Epoch 62/225\n",
            "310/310 - 2s - loss: 1.5384 - accuracy: 0.3731 - val_loss: 1.4729 - val_accuracy: 0.4023\n",
            "Epoch 63/225\n",
            "310/310 - 2s - loss: 1.5380 - accuracy: 0.3767 - val_loss: 1.4737 - val_accuracy: 0.3946\n",
            "Epoch 64/225\n",
            "310/310 - 2s - loss: 1.5360 - accuracy: 0.3773 - val_loss: 1.4742 - val_accuracy: 0.4061\n",
            "Epoch 65/225\n",
            "310/310 - 2s - loss: 1.5370 - accuracy: 0.3731 - val_loss: 1.4718 - val_accuracy: 0.3946\n",
            "Epoch 66/225\n",
            "310/310 - 2s - loss: 1.5338 - accuracy: 0.3780 - val_loss: 1.4695 - val_accuracy: 0.3985\n",
            "Epoch 67/225\n",
            "310/310 - 2s - loss: 1.5376 - accuracy: 0.3801 - val_loss: 1.4761 - val_accuracy: 0.4023\n",
            "Epoch 68/225\n",
            "310/310 - 2s - loss: 1.5343 - accuracy: 0.3770 - val_loss: 1.4691 - val_accuracy: 0.4023\n",
            "Epoch 69/225\n",
            "310/310 - 2s - loss: 1.5321 - accuracy: 0.3761 - val_loss: 1.4682 - val_accuracy: 0.4023\n",
            "Epoch 70/225\n",
            "310/310 - 2s - loss: 1.5310 - accuracy: 0.3790 - val_loss: 1.4693 - val_accuracy: 0.4100\n",
            "Epoch 71/225\n",
            "310/310 - 2s - loss: 1.5296 - accuracy: 0.3785 - val_loss: 1.4672 - val_accuracy: 0.3985\n",
            "Epoch 72/225\n",
            "310/310 - 2s - loss: 1.5326 - accuracy: 0.3794 - val_loss: 1.4664 - val_accuracy: 0.4138\n",
            "Epoch 73/225\n",
            "310/310 - 2s - loss: 1.5289 - accuracy: 0.3765 - val_loss: 1.4671 - val_accuracy: 0.3985\n",
            "Epoch 74/225\n",
            "310/310 - 2s - loss: 1.5292 - accuracy: 0.3775 - val_loss: 1.4702 - val_accuracy: 0.3985\n",
            "Epoch 75/225\n",
            "310/310 - 2s - loss: 1.5331 - accuracy: 0.3735 - val_loss: 1.4662 - val_accuracy: 0.4023\n",
            "Epoch 76/225\n",
            "310/310 - 2s - loss: 1.5285 - accuracy: 0.3770 - val_loss: 1.4651 - val_accuracy: 0.4023\n",
            "Epoch 77/225\n",
            "310/310 - 2s - loss: 1.5278 - accuracy: 0.3744 - val_loss: 1.4609 - val_accuracy: 0.3946\n",
            "Epoch 78/225\n",
            "310/310 - 2s - loss: 1.5276 - accuracy: 0.3775 - val_loss: 1.4663 - val_accuracy: 0.4100\n",
            "Epoch 79/225\n",
            "310/310 - 2s - loss: 1.5290 - accuracy: 0.3809 - val_loss: 1.4625 - val_accuracy: 0.4100\n",
            "Epoch 80/225\n",
            "310/310 - 2s - loss: 1.5274 - accuracy: 0.3774 - val_loss: 1.4650 - val_accuracy: 0.4023\n",
            "Epoch 81/225\n",
            "310/310 - 2s - loss: 1.5262 - accuracy: 0.3843 - val_loss: 1.4644 - val_accuracy: 0.3985\n",
            "Epoch 82/225\n",
            "310/310 - 2s - loss: 1.5308 - accuracy: 0.3739 - val_loss: 1.4651 - val_accuracy: 0.4100\n",
            "Epoch 83/225\n",
            "310/310 - 2s - loss: 1.5261 - accuracy: 0.3776 - val_loss: 1.4605 - val_accuracy: 0.4061\n",
            "Epoch 84/225\n",
            "310/310 - 2s - loss: 1.5216 - accuracy: 0.3834 - val_loss: 1.4622 - val_accuracy: 0.4138\n",
            "Epoch 85/225\n",
            "310/310 - 2s - loss: 1.5248 - accuracy: 0.3765 - val_loss: 1.4625 - val_accuracy: 0.3985\n",
            "Epoch 86/225\n",
            "310/310 - 2s - loss: 1.5211 - accuracy: 0.3834 - val_loss: 1.4626 - val_accuracy: 0.4061\n",
            "Epoch 87/225\n",
            "310/310 - 2s - loss: 1.5198 - accuracy: 0.3824 - val_loss: 1.4636 - val_accuracy: 0.3985\n",
            "Epoch 88/225\n",
            "310/310 - 2s - loss: 1.5229 - accuracy: 0.3823 - val_loss: 1.4650 - val_accuracy: 0.4061\n",
            "Epoch 89/225\n",
            "310/310 - 2s - loss: 1.5208 - accuracy: 0.3813 - val_loss: 1.4583 - val_accuracy: 0.4061\n",
            "Epoch 90/225\n",
            "310/310 - 2s - loss: 1.5215 - accuracy: 0.3835 - val_loss: 1.4605 - val_accuracy: 0.4061\n",
            "Epoch 91/225\n",
            "310/310 - 2s - loss: 1.5221 - accuracy: 0.3849 - val_loss: 1.4584 - val_accuracy: 0.4100\n",
            "Epoch 92/225\n",
            "310/310 - 2s - loss: 1.5217 - accuracy: 0.3788 - val_loss: 1.4649 - val_accuracy: 0.4061\n",
            "Epoch 93/225\n",
            "310/310 - 2s - loss: 1.5187 - accuracy: 0.3818 - val_loss: 1.4559 - val_accuracy: 0.4061\n",
            "Epoch 94/225\n",
            "310/310 - 2s - loss: 1.5202 - accuracy: 0.3802 - val_loss: 1.4551 - val_accuracy: 0.4061\n",
            "Epoch 95/225\n",
            "310/310 - 2s - loss: 1.5154 - accuracy: 0.3843 - val_loss: 1.4552 - val_accuracy: 0.4061\n",
            "Epoch 96/225\n",
            "310/310 - 2s - loss: 1.5188 - accuracy: 0.3837 - val_loss: 1.4558 - val_accuracy: 0.3908\n",
            "Epoch 97/225\n",
            "310/310 - 2s - loss: 1.5151 - accuracy: 0.3858 - val_loss: 1.4579 - val_accuracy: 0.4138\n",
            "Epoch 98/225\n",
            "310/310 - 2s - loss: 1.5162 - accuracy: 0.3803 - val_loss: 1.4544 - val_accuracy: 0.4100\n",
            "Epoch 99/225\n",
            "310/310 - 2s - loss: 1.5158 - accuracy: 0.3827 - val_loss: 1.4532 - val_accuracy: 0.4138\n",
            "Epoch 100/225\n",
            "310/310 - 2s - loss: 1.5157 - accuracy: 0.3846 - val_loss: 1.4541 - val_accuracy: 0.4176\n",
            "Epoch 101/225\n",
            "310/310 - 2s - loss: 1.5145 - accuracy: 0.3860 - val_loss: 1.4528 - val_accuracy: 0.4061\n",
            "Epoch 102/225\n",
            "310/310 - 2s - loss: 1.5152 - accuracy: 0.3855 - val_loss: 1.4544 - val_accuracy: 0.4100\n",
            "Epoch 103/225\n",
            "310/310 - 2s - loss: 1.5127 - accuracy: 0.3882 - val_loss: 1.4541 - val_accuracy: 0.4176\n",
            "Epoch 104/225\n",
            "310/310 - 2s - loss: 1.5137 - accuracy: 0.3859 - val_loss: 1.4604 - val_accuracy: 0.4100\n",
            "Epoch 105/225\n",
            "310/310 - 2s - loss: 1.5152 - accuracy: 0.3828 - val_loss: 1.4597 - val_accuracy: 0.4215\n",
            "Epoch 106/225\n",
            "310/310 - 2s - loss: 1.5138 - accuracy: 0.3848 - val_loss: 1.4601 - val_accuracy: 0.4023\n",
            "Epoch 107/225\n",
            "310/310 - 2s - loss: 1.5132 - accuracy: 0.3830 - val_loss: 1.4525 - val_accuracy: 0.4061\n",
            "Epoch 108/225\n",
            "310/310 - 2s - loss: 1.5120 - accuracy: 0.3859 - val_loss: 1.4549 - val_accuracy: 0.3985\n",
            "Epoch 109/225\n",
            "310/310 - 2s - loss: 1.5072 - accuracy: 0.3838 - val_loss: 1.4505 - val_accuracy: 0.4215\n",
            "Epoch 110/225\n",
            "310/310 - 2s - loss: 1.5115 - accuracy: 0.3842 - val_loss: 1.4569 - val_accuracy: 0.4023\n",
            "Epoch 111/225\n",
            "310/310 - 2s - loss: 1.5084 - accuracy: 0.3873 - val_loss: 1.4527 - val_accuracy: 0.4061\n",
            "Epoch 112/225\n",
            "310/310 - 2s - loss: 1.5112 - accuracy: 0.3877 - val_loss: 1.4528 - val_accuracy: 0.4100\n",
            "Epoch 113/225\n",
            "310/310 - 2s - loss: 1.5080 - accuracy: 0.3871 - val_loss: 1.4492 - val_accuracy: 0.4215\n",
            "Epoch 114/225\n",
            "310/310 - 2s - loss: 1.5108 - accuracy: 0.3862 - val_loss: 1.4535 - val_accuracy: 0.4061\n",
            "Epoch 115/225\n",
            "310/310 - 2s - loss: 1.5089 - accuracy: 0.3808 - val_loss: 1.4521 - val_accuracy: 0.4023\n",
            "Epoch 116/225\n",
            "310/310 - 2s - loss: 1.5030 - accuracy: 0.3892 - val_loss: 1.4495 - val_accuracy: 0.3985\n",
            "Epoch 117/225\n",
            "310/310 - 2s - loss: 1.5068 - accuracy: 0.3884 - val_loss: 1.4540 - val_accuracy: 0.4215\n",
            "Epoch 118/225\n",
            "310/310 - 2s - loss: 1.5062 - accuracy: 0.3899 - val_loss: 1.4527 - val_accuracy: 0.4100\n",
            "Epoch 119/225\n",
            "310/310 - 2s - loss: 1.5050 - accuracy: 0.3882 - val_loss: 1.4501 - val_accuracy: 0.4291\n",
            "Epoch 120/225\n",
            "310/310 - 2s - loss: 1.5011 - accuracy: 0.3878 - val_loss: 1.4506 - val_accuracy: 0.4023\n",
            "Epoch 121/225\n",
            "310/310 - 2s - loss: 1.5046 - accuracy: 0.3900 - val_loss: 1.4535 - val_accuracy: 0.3985\n",
            "Epoch 122/225\n",
            "310/310 - 2s - loss: 1.5019 - accuracy: 0.3943 - val_loss: 1.4533 - val_accuracy: 0.3985\n",
            "Epoch 123/225\n",
            "310/310 - 2s - loss: 1.5060 - accuracy: 0.3906 - val_loss: 1.4516 - val_accuracy: 0.4023\n",
            "Epoch 124/225\n",
            "310/310 - 2s - loss: 1.5018 - accuracy: 0.3863 - val_loss: 1.4536 - val_accuracy: 0.3946\n",
            "Epoch 125/225\n",
            "310/310 - 2s - loss: 1.5001 - accuracy: 0.3962 - val_loss: 1.4499 - val_accuracy: 0.4138\n",
            "Epoch 126/225\n",
            "310/310 - 2s - loss: 1.5016 - accuracy: 0.3923 - val_loss: 1.4526 - val_accuracy: 0.4100\n",
            "Epoch 127/225\n",
            "310/310 - 2s - loss: 1.5023 - accuracy: 0.3896 - val_loss: 1.4496 - val_accuracy: 0.4061\n",
            "Epoch 128/225\n",
            "310/310 - 2s - loss: 1.5017 - accuracy: 0.3906 - val_loss: 1.4512 - val_accuracy: 0.4291\n",
            "Epoch 129/225\n",
            "310/310 - 2s - loss: 1.5023 - accuracy: 0.3917 - val_loss: 1.4499 - val_accuracy: 0.4061\n",
            "Epoch 130/225\n",
            "310/310 - 2s - loss: 1.5010 - accuracy: 0.3923 - val_loss: 1.4505 - val_accuracy: 0.4100\n",
            "Epoch 131/225\n",
            "310/310 - 2s - loss: 1.5005 - accuracy: 0.3917 - val_loss: 1.4509 - val_accuracy: 0.3985\n",
            "Epoch 132/225\n",
            "310/310 - 2s - loss: 1.4964 - accuracy: 0.3880 - val_loss: 1.4515 - val_accuracy: 0.4061\n",
            "Epoch 133/225\n",
            "310/310 - 2s - loss: 1.4990 - accuracy: 0.3926 - val_loss: 1.4516 - val_accuracy: 0.3985\n",
            "Epoch 134/225\n",
            "310/310 - 2s - loss: 1.4991 - accuracy: 0.3906 - val_loss: 1.4562 - val_accuracy: 0.4176\n",
            "Epoch 135/225\n",
            "310/310 - 2s - loss: 1.4992 - accuracy: 0.3919 - val_loss: 1.4566 - val_accuracy: 0.4176\n",
            "Epoch 136/225\n",
            "310/310 - 2s - loss: 1.4949 - accuracy: 0.3940 - val_loss: 1.4507 - val_accuracy: 0.3908\n",
            "Epoch 137/225\n",
            "310/310 - 2s - loss: 1.4967 - accuracy: 0.3921 - val_loss: 1.4498 - val_accuracy: 0.4061\n",
            "Epoch 138/225\n",
            "310/310 - 2s - loss: 1.4966 - accuracy: 0.3963 - val_loss: 1.4523 - val_accuracy: 0.4138\n",
            "Epoch 139/225\n",
            "310/310 - 2s - loss: 1.4963 - accuracy: 0.3880 - val_loss: 1.4512 - val_accuracy: 0.4023\n",
            "Epoch 140/225\n",
            "310/310 - 2s - loss: 1.4988 - accuracy: 0.3877 - val_loss: 1.4485 - val_accuracy: 0.3946\n",
            "Epoch 141/225\n",
            "310/310 - 2s - loss: 1.4967 - accuracy: 0.3902 - val_loss: 1.4507 - val_accuracy: 0.4176\n",
            "Epoch 142/225\n",
            "310/310 - 2s - loss: 1.4925 - accuracy: 0.3976 - val_loss: 1.4500 - val_accuracy: 0.4100\n",
            "Epoch 143/225\n",
            "310/310 - 2s - loss: 1.4946 - accuracy: 0.3933 - val_loss: 1.4547 - val_accuracy: 0.3831\n",
            "Epoch 144/225\n",
            "310/310 - 2s - loss: 1.4974 - accuracy: 0.3885 - val_loss: 1.4557 - val_accuracy: 0.4138\n",
            "Epoch 145/225\n",
            "310/310 - 2s - loss: 1.4962 - accuracy: 0.3933 - val_loss: 1.4517 - val_accuracy: 0.3985\n",
            "Epoch 146/225\n",
            "310/310 - 2s - loss: 1.4937 - accuracy: 0.3944 - val_loss: 1.4535 - val_accuracy: 0.4023\n",
            "Epoch 147/225\n",
            "310/310 - 2s - loss: 1.4928 - accuracy: 0.3950 - val_loss: 1.4504 - val_accuracy: 0.3985\n",
            "Epoch 148/225\n",
            "310/310 - 2s - loss: 1.4941 - accuracy: 0.3918 - val_loss: 1.4499 - val_accuracy: 0.4023\n",
            "Epoch 149/225\n",
            "310/310 - 2s - loss: 1.4903 - accuracy: 0.3914 - val_loss: 1.4523 - val_accuracy: 0.3985\n",
            "Epoch 150/225\n",
            "310/310 - 2s - loss: 1.4941 - accuracy: 0.3934 - val_loss: 1.4520 - val_accuracy: 0.4023\n",
            "Epoch 151/225\n",
            "310/310 - 2s - loss: 1.4922 - accuracy: 0.3970 - val_loss: 1.4497 - val_accuracy: 0.3908\n",
            "Epoch 152/225\n",
            "310/310 - 2s - loss: 1.4930 - accuracy: 0.3954 - val_loss: 1.4540 - val_accuracy: 0.4138\n",
            "Epoch 153/225\n",
            "310/310 - 2s - loss: 1.4899 - accuracy: 0.3977 - val_loss: 1.4496 - val_accuracy: 0.4100\n",
            "Epoch 154/225\n",
            "310/310 - 2s - loss: 1.4893 - accuracy: 0.3926 - val_loss: 1.4516 - val_accuracy: 0.3908\n",
            "Epoch 155/225\n",
            "310/310 - 2s - loss: 1.4900 - accuracy: 0.3921 - val_loss: 1.4503 - val_accuracy: 0.4100\n",
            "Epoch 156/225\n",
            "310/310 - 2s - loss: 1.4924 - accuracy: 0.3956 - val_loss: 1.4505 - val_accuracy: 0.4061\n",
            "Epoch 157/225\n",
            "310/310 - 2s - loss: 1.4876 - accuracy: 0.3955 - val_loss: 1.4498 - val_accuracy: 0.4023\n",
            "Epoch 158/225\n",
            "310/310 - 2s - loss: 1.4865 - accuracy: 0.4011 - val_loss: 1.4506 - val_accuracy: 0.4138\n",
            "Epoch 159/225\n",
            "310/310 - 2s - loss: 1.4865 - accuracy: 0.3946 - val_loss: 1.4503 - val_accuracy: 0.4100\n",
            "Epoch 160/225\n",
            "310/310 - 2s - loss: 1.4898 - accuracy: 0.3968 - val_loss: 1.4512 - val_accuracy: 0.3985\n",
            "Epoch 161/225\n",
            "310/310 - 2s - loss: 1.4883 - accuracy: 0.3951 - val_loss: 1.4491 - val_accuracy: 0.4023\n",
            "Epoch 162/225\n",
            "310/310 - 2s - loss: 1.4844 - accuracy: 0.3921 - val_loss: 1.4525 - val_accuracy: 0.3908\n",
            "Epoch 163/225\n",
            "310/310 - 2s - loss: 1.4862 - accuracy: 0.3947 - val_loss: 1.4488 - val_accuracy: 0.4138\n",
            "Epoch 164/225\n",
            "310/310 - 2s - loss: 1.4830 - accuracy: 0.3950 - val_loss: 1.4513 - val_accuracy: 0.4061\n",
            "Epoch 165/225\n",
            "310/310 - 2s - loss: 1.4882 - accuracy: 0.3953 - val_loss: 1.4476 - val_accuracy: 0.4100\n",
            "Epoch 166/225\n",
            "310/310 - 2s - loss: 1.4840 - accuracy: 0.3996 - val_loss: 1.4483 - val_accuracy: 0.4100\n",
            "Epoch 167/225\n",
            "310/310 - 2s - loss: 1.4813 - accuracy: 0.4010 - val_loss: 1.4465 - val_accuracy: 0.4023\n",
            "Epoch 168/225\n",
            "310/310 - 2s - loss: 1.4843 - accuracy: 0.3965 - val_loss: 1.4492 - val_accuracy: 0.3946\n",
            "Epoch 169/225\n",
            "310/310 - 2s - loss: 1.4796 - accuracy: 0.3995 - val_loss: 1.4499 - val_accuracy: 0.4061\n",
            "Epoch 170/225\n",
            "310/310 - 2s - loss: 1.4845 - accuracy: 0.3983 - val_loss: 1.4483 - val_accuracy: 0.4061\n",
            "Epoch 171/225\n",
            "310/310 - 2s - loss: 1.4796 - accuracy: 0.3986 - val_loss: 1.4494 - val_accuracy: 0.3985\n",
            "Epoch 172/225\n",
            "310/310 - 2s - loss: 1.4837 - accuracy: 0.3986 - val_loss: 1.4558 - val_accuracy: 0.4138\n",
            "Epoch 173/225\n",
            "310/310 - 2s - loss: 1.4815 - accuracy: 0.3963 - val_loss: 1.4459 - val_accuracy: 0.3946\n",
            "Epoch 174/225\n",
            "310/310 - 2s - loss: 1.4838 - accuracy: 0.4014 - val_loss: 1.4500 - val_accuracy: 0.4100\n",
            "Epoch 175/225\n",
            "310/310 - 2s - loss: 1.4800 - accuracy: 0.4035 - val_loss: 1.4479 - val_accuracy: 0.3985\n",
            "Epoch 176/225\n",
            "310/310 - 2s - loss: 1.4834 - accuracy: 0.3994 - val_loss: 1.4483 - val_accuracy: 0.4176\n",
            "Epoch 177/225\n",
            "310/310 - 2s - loss: 1.4781 - accuracy: 0.3994 - val_loss: 1.4472 - val_accuracy: 0.4061\n",
            "Epoch 178/225\n",
            "310/310 - 2s - loss: 1.4810 - accuracy: 0.3971 - val_loss: 1.4498 - val_accuracy: 0.4100\n",
            "Epoch 179/225\n",
            "310/310 - 2s - loss: 1.4782 - accuracy: 0.3998 - val_loss: 1.4453 - val_accuracy: 0.4023\n",
            "Epoch 180/225\n",
            "310/310 - 2s - loss: 1.4759 - accuracy: 0.4022 - val_loss: 1.4503 - val_accuracy: 0.4215\n",
            "Epoch 181/225\n",
            "310/310 - 2s - loss: 1.4759 - accuracy: 0.3995 - val_loss: 1.4470 - val_accuracy: 0.3946\n",
            "Epoch 182/225\n",
            "310/310 - 2s - loss: 1.4775 - accuracy: 0.4017 - val_loss: 1.4488 - val_accuracy: 0.4138\n",
            "Epoch 183/225\n",
            "310/310 - 2s - loss: 1.4748 - accuracy: 0.4005 - val_loss: 1.4509 - val_accuracy: 0.4061\n",
            "Epoch 184/225\n",
            "310/310 - 2s - loss: 1.4753 - accuracy: 0.3999 - val_loss: 1.4505 - val_accuracy: 0.4023\n",
            "Epoch 185/225\n",
            "310/310 - 2s - loss: 1.4753 - accuracy: 0.3984 - val_loss: 1.4462 - val_accuracy: 0.4215\n",
            "Epoch 186/225\n",
            "310/310 - 2s - loss: 1.4767 - accuracy: 0.4012 - val_loss: 1.4446 - val_accuracy: 0.4023\n",
            "Epoch 187/225\n",
            "310/310 - 2s - loss: 1.4743 - accuracy: 0.4014 - val_loss: 1.4479 - val_accuracy: 0.4100\n",
            "Epoch 188/225\n",
            "310/310 - 2s - loss: 1.4769 - accuracy: 0.4025 - val_loss: 1.4565 - val_accuracy: 0.4253\n",
            "Epoch 189/225\n",
            "310/310 - 2s - loss: 1.4744 - accuracy: 0.4023 - val_loss: 1.4498 - val_accuracy: 0.3946\n",
            "Epoch 190/225\n",
            "310/310 - 2s - loss: 1.4715 - accuracy: 0.4008 - val_loss: 1.4461 - val_accuracy: 0.4176\n",
            "Epoch 191/225\n",
            "310/310 - 2s - loss: 1.4732 - accuracy: 0.4059 - val_loss: 1.4513 - val_accuracy: 0.4100\n",
            "Epoch 192/225\n",
            "310/310 - 2s - loss: 1.4707 - accuracy: 0.4030 - val_loss: 1.4468 - val_accuracy: 0.4138\n",
            "Epoch 193/225\n",
            "310/310 - 2s - loss: 1.4743 - accuracy: 0.4058 - val_loss: 1.4506 - val_accuracy: 0.3946\n",
            "Epoch 194/225\n",
            "310/310 - 2s - loss: 1.4737 - accuracy: 0.4019 - val_loss: 1.4513 - val_accuracy: 0.4291\n",
            "Epoch 195/225\n",
            "310/310 - 2s - loss: 1.4712 - accuracy: 0.4012 - val_loss: 1.4466 - val_accuracy: 0.3985\n",
            "Epoch 196/225\n",
            "310/310 - 2s - loss: 1.4697 - accuracy: 0.4047 - val_loss: 1.4474 - val_accuracy: 0.4061\n",
            "Epoch 197/225\n",
            "310/310 - 2s - loss: 1.4703 - accuracy: 0.3994 - val_loss: 1.4446 - val_accuracy: 0.4023\n",
            "Epoch 198/225\n",
            "310/310 - 2s - loss: 1.4725 - accuracy: 0.4006 - val_loss: 1.4468 - val_accuracy: 0.4023\n",
            "Epoch 199/225\n",
            "310/310 - 2s - loss: 1.4689 - accuracy: 0.4102 - val_loss: 1.4538 - val_accuracy: 0.4023\n",
            "Epoch 200/225\n",
            "310/310 - 2s - loss: 1.4680 - accuracy: 0.4084 - val_loss: 1.4462 - val_accuracy: 0.4100\n",
            "Epoch 201/225\n",
            "310/310 - 2s - loss: 1.4674 - accuracy: 0.4037 - val_loss: 1.4479 - val_accuracy: 0.4215\n",
            "Epoch 202/225\n",
            "310/310 - 2s - loss: 1.4684 - accuracy: 0.4072 - val_loss: 1.4478 - val_accuracy: 0.4100\n",
            "Epoch 203/225\n",
            "310/310 - 2s - loss: 1.4701 - accuracy: 0.4069 - val_loss: 1.4472 - val_accuracy: 0.4061\n",
            "Epoch 204/225\n",
            "310/310 - 2s - loss: 1.4671 - accuracy: 0.4052 - val_loss: 1.4447 - val_accuracy: 0.4061\n",
            "Epoch 205/225\n",
            "310/310 - 2s - loss: 1.4650 - accuracy: 0.4046 - val_loss: 1.4477 - val_accuracy: 0.4100\n",
            "Epoch 206/225\n",
            "310/310 - 2s - loss: 1.4682 - accuracy: 0.4055 - val_loss: 1.4490 - val_accuracy: 0.3946\n",
            "Epoch 207/225\n",
            "310/310 - 2s - loss: 1.4650 - accuracy: 0.4030 - val_loss: 1.4462 - val_accuracy: 0.4061\n",
            "Epoch 208/225\n",
            "310/310 - 2s - loss: 1.4674 - accuracy: 0.4048 - val_loss: 1.4460 - val_accuracy: 0.4061\n",
            "Epoch 209/225\n",
            "310/310 - 2s - loss: 1.4656 - accuracy: 0.4035 - val_loss: 1.4433 - val_accuracy: 0.3985\n",
            "Epoch 210/225\n",
            "310/310 - 2s - loss: 1.4689 - accuracy: 0.4045 - val_loss: 1.4475 - val_accuracy: 0.4215\n",
            "Epoch 211/225\n",
            "310/310 - 2s - loss: 1.4699 - accuracy: 0.4046 - val_loss: 1.4476 - val_accuracy: 0.4061\n",
            "Epoch 212/225\n",
            "310/310 - 2s - loss: 1.4612 - accuracy: 0.4023 - val_loss: 1.4510 - val_accuracy: 0.4023\n",
            "Epoch 213/225\n",
            "310/310 - 2s - loss: 1.4643 - accuracy: 0.4020 - val_loss: 1.4524 - val_accuracy: 0.4253\n",
            "Epoch 214/225\n",
            "310/310 - 2s - loss: 1.4630 - accuracy: 0.4089 - val_loss: 1.4464 - val_accuracy: 0.4138\n",
            "Epoch 215/225\n",
            "310/310 - 2s - loss: 1.4627 - accuracy: 0.4106 - val_loss: 1.4435 - val_accuracy: 0.4253\n",
            "Epoch 216/225\n",
            "310/310 - 2s - loss: 1.4559 - accuracy: 0.4095 - val_loss: 1.4429 - val_accuracy: 0.4253\n",
            "Epoch 217/225\n",
            "310/310 - 2s - loss: 1.4627 - accuracy: 0.4079 - val_loss: 1.4487 - val_accuracy: 0.4291\n",
            "Epoch 218/225\n",
            "310/310 - 2s - loss: 1.4566 - accuracy: 0.4076 - val_loss: 1.4453 - val_accuracy: 0.4023\n",
            "Epoch 219/225\n",
            "310/310 - 2s - loss: 1.4627 - accuracy: 0.4128 - val_loss: 1.4459 - val_accuracy: 0.4176\n",
            "Epoch 220/225\n",
            "310/310 - 2s - loss: 1.4599 - accuracy: 0.4086 - val_loss: 1.4477 - val_accuracy: 0.4215\n",
            "Epoch 221/225\n",
            "310/310 - 2s - loss: 1.4562 - accuracy: 0.4098 - val_loss: 1.4450 - val_accuracy: 0.4100\n",
            "Epoch 222/225\n",
            "310/310 - 2s - loss: 1.4663 - accuracy: 0.4067 - val_loss: 1.4484 - val_accuracy: 0.4330\n",
            "Epoch 223/225\n",
            "310/310 - 2s - loss: 1.4553 - accuracy: 0.4133 - val_loss: 1.4467 - val_accuracy: 0.4023\n",
            "Epoch 224/225\n",
            "310/310 - 2s - loss: 1.4593 - accuracy: 0.4089 - val_loss: 1.4435 - val_accuracy: 0.4176\n",
            "Epoch 225/225\n",
            "310/310 - 2s - loss: 1.4605 - accuracy: 0.4118 - val_loss: 1.4427 - val_accuracy: 0.4253\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "70/70 [==============================] - 0s 4ms/step - loss: 1.4765 - accuracy: 0.4004\n",
            "\n",
            "Test loss =  1.4764827489852905\n",
            "Accuracy of the model =  0.40035825967788696\n",
            "F-score of the model =  0.3720704443856704\n",
            "Confusion Matrix: \n",
            "[[260  29   5  46  13   6]\n",
            " [ 94 132  22  42  36  60]\n",
            " [ 57  61  29  58  43 123]\n",
            " [105  38  13 121  55  46]\n",
            " [ 24  46  12  56 118  97]\n",
            " [ 10  46  28  23  45 234]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIIC7DML4HOw"
      },
      "source": [
        "# **2. Mel Spectrogram model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vUmhh-4z18TG",
        "outputId": "07722206-aa37-4e42-b47b-0bb8e6deb569"
      },
      "source": [
        "def train_model_mel():\n",
        "  #Splitting data 70% training , 30% testing\n",
        "  x_mel_train, x_mel_test, y_mel_train, y_mel_test = train_test_split(x_mel, y, test_size=0.3, random_state=42)\n",
        "  \n",
        "  # Reshaping training data\n",
        "  x_mel_train = x_mel_train.reshape(-1, 128, 216, 1)\n",
        "  x_mel_test = x_mel_test.reshape(-1, 128, 216, 1)\n",
        "  # Normalizing data\n",
        "  x_mel_train = x_mel_train.astype('float32')\n",
        "  x_mel_test = x_mel_test.astype('float32')\n",
        "  #x_mel_train = librosa.util.normalize(x_mel_train)\n",
        "  #x_mel_test = librosa.util.normalize(x_mel_test)\n",
        "  x_mel_train = x_mel_train / 255.\n",
        "  x_mel_test = x_mel_test / 255.\n",
        "\n",
        "  #print(x_mel_train.shape, x_mel_test.shape,y_mel_train[0],y_mel_test[0])\n",
        "  #print(x_mel_train.shape, x_mel_test.shape)\n",
        "\n",
        "  #Splitting training data 5% validation\n",
        "  x_mel_train, x_mel_valid, y_mel_train, y_mel_valid = train_test_split(x_mel_train, y_mel_train, test_size=0.05, random_state=42)\n",
        "\n",
        "  #Data Augmentation to reduce overfitting\n",
        "  #Noise\n",
        "  print(\"Before augmentation training x and y size: \",x_mel_train.shape,y_mel_train.shape)\n",
        "  noise_arr = []\n",
        "  for i in range(x_mel_train.shape[0]):\n",
        "    noise_arr.append(noise(x_mel_train[i]))\n",
        "  noise_arr = np.array(noise_arr)\n",
        "  x_mel_train = np.append(x_mel_train,noise_arr,axis=0) \n",
        "  y_mel_train = np.append(y_mel_train,y_mel_train)\n",
        "  print(\"After augmentation training x and y size: \",x_mel_train.shape,y_mel_train.shape)\n",
        "  \n",
        "  # Change the labels from categorical to one-hot encoding\n",
        "  y_mel_train = to_categorical(y_mel_train)\n",
        "  y_mel_test = to_categorical(y_mel_test)\n",
        "  y_mel_valid = to_categorical(y_mel_valid)\n",
        "\n",
        "  #print(x_mel_train.shape, x_mel_test.shape,x_mel_valid.shape,y_mel_valid.shape)\n",
        "  \n",
        "  # Building model\n",
        "  mel_model = Sequential()\n",
        "  mel_model.add(Conv2D(32, kernel_size=(11, 11),activation='relu',input_shape=(128,216,1),padding='valid'))\n",
        "  mel_model.add(Conv2D(32, kernel_size=(7, 7),activation='relu',padding='valid'))\n",
        "  mel_model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',padding='valid'))\n",
        "  mel_model.add(MaxPooling2D((2, 2),padding='valid'))\n",
        "  mel_model.add(Dropout(0.25))\n",
        "  mel_model.add(Conv2D(64, kernel_size=(3, 3),activation='relu',padding='valid'))\n",
        "  mel_model.add(Conv2D(64, kernel_size=(3, 3),activation='relu',padding='valid'))\n",
        "  #mel_model.add(BatchNormalization())\n",
        "  mel_model.add(MaxPooling2D((2, 2),padding='valid'))\n",
        "  mel_model.add(Dropout(0.25))\n",
        "  mel_model.add(Conv2D(128, kernel_size=(3, 3),activation='relu',padding='valid'))\n",
        "  mel_model.add(Conv2D(128, kernel_size=(3, 3),activation='relu',padding='valid'))\n",
        "  #mel_model.add(BatchNormalization())\n",
        "  mel_model.add(MaxPooling2D((2, 2),padding='valid'))\n",
        "  mel_model.add(Dropout(0.25))\n",
        "  mel_model.add(Conv2D(256, kernel_size=(3, 3),activation='relu',padding='valid'))\n",
        "  mel_model.add(Conv2D(256, kernel_size=(3, 3),activation='relu',padding='valid'))\n",
        "  mel_model.add(Conv2D(256, kernel_size=(3, 3),activation='relu',padding='valid'))\n",
        "  #mel_model.add(BatchNormalization())\n",
        "  mel_model.add(MaxPooling2D((2, 2),padding='valid'))\n",
        "  mel_model.add(Dropout(0.25))\n",
        "  mel_model.add(Flatten())\n",
        "  mel_model.add(Dense(128, activation='relu'))\n",
        "  #mel_model.add(BatchNormalization())\n",
        "  mel_model.add(Dropout(0.25))\n",
        "  mel_model.add(Dense(6, activation='softmax'))\n",
        "  # Compiling model using ADAM optimizer\n",
        "  adam = keras.optimizers.Adam(learning_rate=0.00001)\n",
        "  mel_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=adam,metrics=['accuracy'])\n",
        "  # Model summary\n",
        "  print(\"\\nModel Inspection\\n\")\n",
        "  mel_model.summary()\n",
        "  # Training model\n",
        "  print(\"\\nModel training\\n\")\n",
        "  mel_train_history = mel_model.fit(x_mel_train, y_mel_train, batch_size=128,epochs=100,verbose=2,validation_data=(x_mel_valid, y_mel_valid))\n",
        "\n",
        "  # Plotting the Train Valid Loss Graph\n",
        "  plt.plot(mel_train_history.history['loss'])\n",
        "  plt.plot(mel_train_history.history['val_loss'])\n",
        "  plt.title('Model Loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  # Calculating accuracy of model\n",
        "  score = mel_model.evaluate(x_mel_test, y_mel_test)\n",
        "  print(\"\\nTest loss = \",score[0])\n",
        "  print(\"Accuracy of the model = \",score[1])\n",
        "  predicted_classes = mel_model.predict(x_mel_test)\n",
        "  predicted_classes = np.argmax(predicted_classes, axis=1)\n",
        "  y_mel_test = np.argmax(y_mel_test, axis=1)\n",
        "  print(\"F-score of the model = \",f1_score(y_mel_test,predicted_classes,average='macro'))\n",
        "  print(\"Confusion Matrix: \")\n",
        "  print(confusion_matrix(y_mel_test,predicted_classes))\n",
        "\n",
        "  \n",
        "\n",
        "train_model_mel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before augmentation training x and y size:  (4948, 128, 216, 1) (4948,)\n",
            "After augmentation training x and y size:  (9896, 128, 216, 1) (9896,)\n",
            "\n",
            "Model Inspection\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 118, 206, 32)      3904      \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 112, 200, 32)      50208     \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 110, 198, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 55, 99, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 55, 99, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 53, 97, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 51, 95, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 25, 47, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 25, 47, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 23, 45, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 21, 43, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 10, 21, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 10, 21, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 8, 19, 256)        295168    \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 6, 17, 256)        590080    \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 4, 15, 256)        590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 2, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3584)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               458880    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 6)                 774       \n",
            "=================================================================\n",
            "Total params: 2,275,206\n",
            "Trainable params: 2,275,206\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Model training\n",
            "\n",
            "Epoch 1/100\n",
            "78/78 - 44s - loss: 1.7826 - accuracy: 0.2328 - val_loss: 1.7626 - val_accuracy: 0.2299\n",
            "Epoch 2/100\n",
            "78/78 - 33s - loss: 1.7172 - accuracy: 0.2360 - val_loss: 1.7021 - val_accuracy: 0.3065\n",
            "Epoch 3/100\n",
            "78/78 - 33s - loss: 1.6913 - accuracy: 0.2949 - val_loss: 1.6704 - val_accuracy: 0.2912\n",
            "Epoch 4/100\n",
            "78/78 - 33s - loss: 1.6750 - accuracy: 0.3164 - val_loss: 1.6539 - val_accuracy: 0.3103\n",
            "Epoch 5/100\n",
            "78/78 - 33s - loss: 1.6474 - accuracy: 0.3095 - val_loss: 1.6291 - val_accuracy: 0.2989\n",
            "Epoch 6/100\n",
            "78/78 - 33s - loss: 1.6221 - accuracy: 0.3113 - val_loss: 1.6050 - val_accuracy: 0.3257\n",
            "Epoch 7/100\n",
            "78/78 - 33s - loss: 1.6047 - accuracy: 0.3179 - val_loss: 1.5770 - val_accuracy: 0.3372\n",
            "Epoch 8/100\n",
            "78/78 - 33s - loss: 1.5965 - accuracy: 0.3220 - val_loss: 1.5741 - val_accuracy: 0.3487\n",
            "Epoch 9/100\n",
            "78/78 - 33s - loss: 1.5784 - accuracy: 0.3311 - val_loss: 1.5442 - val_accuracy: 0.3640\n",
            "Epoch 10/100\n",
            "78/78 - 33s - loss: 1.5674 - accuracy: 0.3394 - val_loss: 1.5563 - val_accuracy: 0.3563\n",
            "Epoch 11/100\n",
            "78/78 - 33s - loss: 1.5534 - accuracy: 0.3492 - val_loss: 1.5218 - val_accuracy: 0.3831\n",
            "Epoch 12/100\n",
            "78/78 - 33s - loss: 1.5424 - accuracy: 0.3501 - val_loss: 1.5077 - val_accuracy: 0.3793\n",
            "Epoch 13/100\n",
            "78/78 - 33s - loss: 1.5352 - accuracy: 0.3529 - val_loss: 1.5168 - val_accuracy: 0.3831\n",
            "Epoch 14/100\n",
            "78/78 - 33s - loss: 1.5199 - accuracy: 0.3649 - val_loss: 1.5013 - val_accuracy: 0.3908\n",
            "Epoch 15/100\n",
            "78/78 - 33s - loss: 1.5167 - accuracy: 0.3662 - val_loss: 1.4916 - val_accuracy: 0.3870\n",
            "Epoch 16/100\n",
            "78/78 - 33s - loss: 1.5043 - accuracy: 0.3741 - val_loss: 1.4757 - val_accuracy: 0.3985\n",
            "Epoch 17/100\n",
            "78/78 - 33s - loss: 1.4971 - accuracy: 0.3775 - val_loss: 1.4618 - val_accuracy: 0.4023\n",
            "Epoch 18/100\n",
            "78/78 - 33s - loss: 1.4916 - accuracy: 0.3813 - val_loss: 1.4849 - val_accuracy: 0.3985\n",
            "Epoch 19/100\n",
            "78/78 - 33s - loss: 1.4872 - accuracy: 0.3851 - val_loss: 1.4726 - val_accuracy: 0.3985\n",
            "Epoch 20/100\n",
            "78/78 - 33s - loss: 1.4802 - accuracy: 0.3843 - val_loss: 1.4546 - val_accuracy: 0.3985\n",
            "Epoch 21/100\n",
            "78/78 - 33s - loss: 1.4762 - accuracy: 0.3925 - val_loss: 1.4557 - val_accuracy: 0.4176\n",
            "Epoch 22/100\n",
            "78/78 - 33s - loss: 1.4744 - accuracy: 0.3934 - val_loss: 1.4557 - val_accuracy: 0.4061\n",
            "Epoch 23/100\n",
            "78/78 - 33s - loss: 1.4705 - accuracy: 0.3872 - val_loss: 1.4500 - val_accuracy: 0.4100\n",
            "Epoch 24/100\n",
            "78/78 - 33s - loss: 1.4676 - accuracy: 0.3963 - val_loss: 1.4518 - val_accuracy: 0.4100\n",
            "Epoch 25/100\n",
            "78/78 - 33s - loss: 1.4635 - accuracy: 0.3952 - val_loss: 1.4364 - val_accuracy: 0.4253\n",
            "Epoch 26/100\n",
            "78/78 - 33s - loss: 1.4604 - accuracy: 0.3959 - val_loss: 1.4345 - val_accuracy: 0.4176\n",
            "Epoch 27/100\n",
            "78/78 - 33s - loss: 1.4582 - accuracy: 0.3983 - val_loss: 1.4357 - val_accuracy: 0.4253\n",
            "Epoch 28/100\n",
            "78/78 - 33s - loss: 1.4524 - accuracy: 0.3983 - val_loss: 1.4123 - val_accuracy: 0.4215\n",
            "Epoch 29/100\n",
            "78/78 - 33s - loss: 1.4494 - accuracy: 0.4002 - val_loss: 1.4170 - val_accuracy: 0.4176\n",
            "Epoch 30/100\n",
            "78/78 - 33s - loss: 1.4504 - accuracy: 0.4033 - val_loss: 1.4132 - val_accuracy: 0.4291\n",
            "Epoch 31/100\n",
            "78/78 - 33s - loss: 1.4460 - accuracy: 0.4040 - val_loss: 1.4050 - val_accuracy: 0.4215\n",
            "Epoch 32/100\n",
            "78/78 - 33s - loss: 1.4448 - accuracy: 0.4057 - val_loss: 1.4010 - val_accuracy: 0.4291\n",
            "Epoch 33/100\n",
            "78/78 - 33s - loss: 1.4388 - accuracy: 0.4138 - val_loss: 1.4069 - val_accuracy: 0.4291\n",
            "Epoch 34/100\n",
            "78/78 - 33s - loss: 1.4351 - accuracy: 0.4074 - val_loss: 1.3952 - val_accuracy: 0.4291\n",
            "Epoch 35/100\n",
            "78/78 - 33s - loss: 1.4365 - accuracy: 0.4037 - val_loss: 1.4029 - val_accuracy: 0.4368\n",
            "Epoch 36/100\n",
            "78/78 - 34s - loss: 1.4336 - accuracy: 0.4084 - val_loss: 1.3912 - val_accuracy: 0.4330\n",
            "Epoch 37/100\n",
            "78/78 - 33s - loss: 1.4320 - accuracy: 0.4101 - val_loss: 1.3895 - val_accuracy: 0.4444\n",
            "Epoch 38/100\n",
            "78/78 - 33s - loss: 1.4319 - accuracy: 0.4112 - val_loss: 1.3876 - val_accuracy: 0.4253\n",
            "Epoch 39/100\n",
            "78/78 - 33s - loss: 1.4233 - accuracy: 0.4141 - val_loss: 1.3904 - val_accuracy: 0.4444\n",
            "Epoch 40/100\n",
            "78/78 - 33s - loss: 1.4253 - accuracy: 0.4188 - val_loss: 1.3787 - val_accuracy: 0.4598\n",
            "Epoch 41/100\n",
            "78/78 - 33s - loss: 1.4264 - accuracy: 0.4120 - val_loss: 1.3894 - val_accuracy: 0.4368\n",
            "Epoch 42/100\n",
            "78/78 - 33s - loss: 1.4222 - accuracy: 0.4216 - val_loss: 1.3830 - val_accuracy: 0.4368\n",
            "Epoch 43/100\n",
            "78/78 - 33s - loss: 1.4219 - accuracy: 0.4130 - val_loss: 1.3738 - val_accuracy: 0.4483\n",
            "Epoch 44/100\n",
            "78/78 - 33s - loss: 1.4177 - accuracy: 0.4188 - val_loss: 1.3682 - val_accuracy: 0.4406\n",
            "Epoch 45/100\n",
            "78/78 - 33s - loss: 1.4133 - accuracy: 0.4208 - val_loss: 1.3675 - val_accuracy: 0.4444\n",
            "Epoch 46/100\n",
            "78/78 - 33s - loss: 1.4138 - accuracy: 0.4213 - val_loss: 1.3648 - val_accuracy: 0.4521\n",
            "Epoch 47/100\n",
            "78/78 - 33s - loss: 1.4087 - accuracy: 0.4265 - val_loss: 1.3667 - val_accuracy: 0.4521\n",
            "Epoch 48/100\n",
            "78/78 - 33s - loss: 1.4121 - accuracy: 0.4216 - val_loss: 1.3712 - val_accuracy: 0.4444\n",
            "Epoch 49/100\n",
            "78/78 - 33s - loss: 1.4063 - accuracy: 0.4232 - val_loss: 1.3549 - val_accuracy: 0.4559\n",
            "Epoch 50/100\n",
            "78/78 - 33s - loss: 1.4020 - accuracy: 0.4281 - val_loss: 1.3560 - val_accuracy: 0.4406\n",
            "Epoch 51/100\n",
            "78/78 - 33s - loss: 1.4031 - accuracy: 0.4250 - val_loss: 1.3613 - val_accuracy: 0.4598\n",
            "Epoch 52/100\n",
            "78/78 - 33s - loss: 1.4058 - accuracy: 0.4213 - val_loss: 1.3569 - val_accuracy: 0.4521\n",
            "Epoch 53/100\n",
            "78/78 - 33s - loss: 1.3981 - accuracy: 0.4256 - val_loss: 1.3555 - val_accuracy: 0.4483\n",
            "Epoch 54/100\n",
            "78/78 - 33s - loss: 1.3970 - accuracy: 0.4309 - val_loss: 1.3514 - val_accuracy: 0.4559\n",
            "Epoch 55/100\n",
            "78/78 - 33s - loss: 1.3920 - accuracy: 0.4318 - val_loss: 1.3501 - val_accuracy: 0.4483\n",
            "Epoch 56/100\n",
            "78/78 - 33s - loss: 1.3902 - accuracy: 0.4355 - val_loss: 1.3479 - val_accuracy: 0.4636\n",
            "Epoch 57/100\n",
            "78/78 - 33s - loss: 1.3907 - accuracy: 0.4276 - val_loss: 1.3461 - val_accuracy: 0.4598\n",
            "Epoch 58/100\n",
            "78/78 - 33s - loss: 1.3900 - accuracy: 0.4320 - val_loss: 1.3494 - val_accuracy: 0.4521\n",
            "Epoch 59/100\n",
            "78/78 - 33s - loss: 1.3874 - accuracy: 0.4361 - val_loss: 1.3434 - val_accuracy: 0.4521\n",
            "Epoch 60/100\n",
            "78/78 - 33s - loss: 1.3855 - accuracy: 0.4361 - val_loss: 1.3383 - val_accuracy: 0.4559\n",
            "Epoch 61/100\n",
            "78/78 - 33s - loss: 1.3850 - accuracy: 0.4309 - val_loss: 1.3399 - val_accuracy: 0.4789\n",
            "Epoch 62/100\n",
            "78/78 - 33s - loss: 1.3785 - accuracy: 0.4421 - val_loss: 1.3462 - val_accuracy: 0.4598\n",
            "Epoch 63/100\n",
            "78/78 - 33s - loss: 1.3821 - accuracy: 0.4402 - val_loss: 1.3375 - val_accuracy: 0.4789\n",
            "Epoch 64/100\n",
            "78/78 - 33s - loss: 1.3746 - accuracy: 0.4425 - val_loss: 1.3326 - val_accuracy: 0.4751\n",
            "Epoch 65/100\n",
            "78/78 - 33s - loss: 1.3718 - accuracy: 0.4396 - val_loss: 1.3306 - val_accuracy: 0.4674\n",
            "Epoch 66/100\n",
            "78/78 - 33s - loss: 1.3701 - accuracy: 0.4440 - val_loss: 1.3389 - val_accuracy: 0.4674\n",
            "Epoch 67/100\n",
            "78/78 - 33s - loss: 1.3667 - accuracy: 0.4463 - val_loss: 1.3259 - val_accuracy: 0.4866\n",
            "Epoch 68/100\n",
            "78/78 - 33s - loss: 1.3711 - accuracy: 0.4404 - val_loss: 1.3269 - val_accuracy: 0.4636\n",
            "Epoch 69/100\n",
            "78/78 - 33s - loss: 1.3604 - accuracy: 0.4483 - val_loss: 1.3241 - val_accuracy: 0.4828\n",
            "Epoch 70/100\n",
            "78/78 - 33s - loss: 1.3611 - accuracy: 0.4435 - val_loss: 1.3261 - val_accuracy: 0.4866\n",
            "Epoch 71/100\n",
            "78/78 - 33s - loss: 1.3628 - accuracy: 0.4428 - val_loss: 1.3254 - val_accuracy: 0.4598\n",
            "Epoch 72/100\n",
            "78/78 - 33s - loss: 1.3595 - accuracy: 0.4488 - val_loss: 1.3191 - val_accuracy: 0.4866\n",
            "Epoch 73/100\n",
            "78/78 - 33s - loss: 1.3611 - accuracy: 0.4447 - val_loss: 1.3136 - val_accuracy: 0.4943\n",
            "Epoch 74/100\n",
            "78/78 - 33s - loss: 1.3516 - accuracy: 0.4501 - val_loss: 1.3154 - val_accuracy: 0.4828\n",
            "Epoch 75/100\n",
            "78/78 - 33s - loss: 1.3473 - accuracy: 0.4529 - val_loss: 1.3159 - val_accuracy: 0.4866\n",
            "Epoch 76/100\n",
            "78/78 - 33s - loss: 1.3523 - accuracy: 0.4542 - val_loss: 1.3189 - val_accuracy: 0.4674\n",
            "Epoch 77/100\n",
            "78/78 - 33s - loss: 1.3486 - accuracy: 0.4534 - val_loss: 1.3184 - val_accuracy: 0.4598\n",
            "Epoch 78/100\n",
            "78/78 - 33s - loss: 1.3455 - accuracy: 0.4571 - val_loss: 1.3146 - val_accuracy: 0.4751\n",
            "Epoch 79/100\n",
            "78/78 - 33s - loss: 1.3510 - accuracy: 0.4568 - val_loss: 1.3138 - val_accuracy: 0.4789\n",
            "Epoch 80/100\n",
            "78/78 - 33s - loss: 1.3403 - accuracy: 0.4547 - val_loss: 1.3101 - val_accuracy: 0.4866\n",
            "Epoch 81/100\n",
            "78/78 - 33s - loss: 1.3402 - accuracy: 0.4581 - val_loss: 1.3033 - val_accuracy: 0.5019\n",
            "Epoch 82/100\n",
            "78/78 - 33s - loss: 1.3398 - accuracy: 0.4547 - val_loss: 1.3065 - val_accuracy: 0.5019\n",
            "Epoch 83/100\n",
            "78/78 - 33s - loss: 1.3352 - accuracy: 0.4593 - val_loss: 1.3106 - val_accuracy: 0.4789\n",
            "Epoch 84/100\n",
            "78/78 - 33s - loss: 1.3349 - accuracy: 0.4580 - val_loss: 1.2999 - val_accuracy: 0.4943\n",
            "Epoch 85/100\n",
            "78/78 - 33s - loss: 1.3279 - accuracy: 0.4650 - val_loss: 1.3034 - val_accuracy: 0.4943\n",
            "Epoch 86/100\n",
            "78/78 - 33s - loss: 1.3316 - accuracy: 0.4589 - val_loss: 1.3012 - val_accuracy: 0.5057\n",
            "Epoch 87/100\n",
            "78/78 - 33s - loss: 1.3278 - accuracy: 0.4648 - val_loss: 1.3041 - val_accuracy: 0.4943\n",
            "Epoch 88/100\n",
            "78/78 - 33s - loss: 1.3251 - accuracy: 0.4668 - val_loss: 1.3143 - val_accuracy: 0.4751\n",
            "Epoch 89/100\n",
            "78/78 - 33s - loss: 1.3229 - accuracy: 0.4667 - val_loss: 1.3011 - val_accuracy: 0.5057\n",
            "Epoch 90/100\n",
            "78/78 - 33s - loss: 1.3231 - accuracy: 0.4667 - val_loss: 1.2997 - val_accuracy: 0.5019\n",
            "Epoch 91/100\n",
            "78/78 - 33s - loss: 1.3152 - accuracy: 0.4699 - val_loss: 1.2961 - val_accuracy: 0.5057\n",
            "Epoch 92/100\n",
            "78/78 - 33s - loss: 1.3116 - accuracy: 0.4732 - val_loss: 1.3011 - val_accuracy: 0.4904\n",
            "Epoch 93/100\n",
            "78/78 - 33s - loss: 1.3132 - accuracy: 0.4703 - val_loss: 1.2970 - val_accuracy: 0.4981\n",
            "Epoch 94/100\n",
            "78/78 - 33s - loss: 1.3114 - accuracy: 0.4681 - val_loss: 1.2938 - val_accuracy: 0.5057\n",
            "Epoch 95/100\n",
            "78/78 - 33s - loss: 1.3094 - accuracy: 0.4686 - val_loss: 1.2901 - val_accuracy: 0.5019\n",
            "Epoch 96/100\n",
            "78/78 - 33s - loss: 1.3025 - accuracy: 0.4772 - val_loss: 1.2991 - val_accuracy: 0.5134\n",
            "Epoch 97/100\n",
            "78/78 - 33s - loss: 1.3079 - accuracy: 0.4705 - val_loss: 1.2896 - val_accuracy: 0.5057\n",
            "Epoch 98/100\n",
            "78/78 - 33s - loss: 1.2971 - accuracy: 0.4749 - val_loss: 1.2912 - val_accuracy: 0.5057\n",
            "Epoch 99/100\n",
            "78/78 - 33s - loss: 1.2982 - accuracy: 0.4806 - val_loss: 1.2906 - val_accuracy: 0.5134\n",
            "Epoch 100/100\n",
            "78/78 - 33s - loss: 1.2898 - accuracy: 0.4819 - val_loss: 1.2840 - val_accuracy: 0.5134\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "70/70 [==============================] - 2s 29ms/step - loss: 1.3155 - accuracy: 0.4872\n",
            "\n",
            "Test loss =  1.3155336380004883\n",
            "Accuracy of the model =  0.487236887216568\n",
            "F-score of the model =  0.4730762949723278\n",
            "Confusion Matrix: \n",
            "[[258  19   7  58  15   2]\n",
            " [ 29 123  28  57  73  76]\n",
            " [ 25  36  68  69  69 104]\n",
            " [ 55  31  30 176  69  17]\n",
            " [  2  26  13  46 224  42]\n",
            " [  0  32  19   6  90 239]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdn8Zxzb3waR"
      },
      "source": [
        "**Simple Code to know the max dimension in the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft_wh39BMkcF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaea1366-c917-43f3-df81-630c41046737"
      },
      "source": [
        "# Max dimensions of zcr and mel spectrogram\n",
        "maxn = 0\n",
        "for i in range(len(x_zcr)):\n",
        "  if len(x_zcr[i][0]) > maxn:\n",
        "    maxn = len(x_zcr[i][0])\n",
        "print(\"Max dimension=\",maxn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max dimension= 216\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}